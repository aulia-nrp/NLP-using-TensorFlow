{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EDA.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMcZhOfa9XhaxPW/X3ZGnJC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVXu4XmD1kID"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbpwo3txxO0_"
      },
      "source": [
        "**Dataset**\n",
        "\n",
        "We gather the data for the dataset by scraping Twitter's tweet that contain words about incidents of sexual violence and harassment from the victim. We scrap #MeToo hashtag which is a social movement against sexual abuse and sexual harassment where people publicize allegations of sex crimes. The phrase \"Me Too\" was initially used in this context on social media in 2006, on Myspace, by sexual harassment survivor and activist Tarana Burke."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCmhCTli0aXx"
      },
      "source": [
        "We collected the data with 4 period time.\n",
        "\n",
        "\n",
        "1.   1st period: 15 April - 23 April 2021\n",
        "2.   2nd period: 23 April - 29 April 2021\n",
        "3.   3rd period: 29 April - 05 May 2021\n",
        "4.   4th period: 05 May - 11 May 2021\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO8s2CYR2XR-"
      },
      "source": [
        "#Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4H8oCTzm1b7X"
      },
      "source": [
        "# 1st period (15 Apr - 23 Apr 2021)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "ncV1-QbTxIup",
        "outputId": "98cc28a8-03a5-4122-9aa5-a6cbf3751ffc"
      },
      "source": [
        "#Import First Dataset\n",
        "url_one = 'https://drive.google.com/file/d/1lTvQke_pO35JgAj1Bzj5ULsA_gno94DQ/view?usp=sharing'\n",
        "file_id_one = url_one.split('/')[-2]\n",
        "csv_url_one = 'https://drive.google.com/uc?id=' + file_id_one\n",
        "df_one = pd.read_csv(csv_url_one)\n",
        "df_one.head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>user_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>420319697</td>\n",
              "      <td>2021-04-23 23:20:32</td>\n",
              "      <td>b\\'\"The ironies of the #MeToo movement are too...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>b\"33979748</td>\n",
              "      <td>2021-04-23 23:20:23</td>\n",
              "      <td>RT @WomenReadWomen: Women in Kuwait have launc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>b\"2891085942</td>\n",
              "      <td>2021-04-23 23:20:19</td>\n",
              "      <td>RT @j_andreamolina: \\\\xe2\\\\x9a\\\\xa0\\\\xef\\\\xb8\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>b\"2383033227</td>\n",
              "      <td>2021-04-23 23:19:13</td>\n",
              "      <td>RT @SammiStitches: Charges brought against the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1060143967872917504</td>\n",
              "      <td>2021-04-23 23:18:41</td>\n",
              "      <td>b\"And the fourth presenter on 26th May is Hann...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ...                                               text\n",
              "0      1  ...  b\\'\"The ironies of the #MeToo movement are too...\n",
              "1      2  ...  RT @WomenReadWomen: Women in Kuwait have launc...\n",
              "2      3  ...  RT @j_andreamolina: \\\\xe2\\\\x9a\\\\xa0\\\\xef\\\\xb8\\...\n",
              "3      4  ...  RT @SammiStitches: Charges brought against the...\n",
              "4      5  ...  b\"And the fourth presenter on 26th May is Hann...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRqYJEAY1_h6",
        "outputId": "874e4081-a91a-46f6-a664-4cfb0bd3ede6"
      },
      "source": [
        "print(\"Shape of 1st period data-> \", df_one.shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of 1st period data->  (6600, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMaMArXn1qTH"
      },
      "source": [
        "# 2nd period (23 Apr - 29 Apr 2021)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "4xaQqAdb1Qym",
        "outputId": "c1dc41fb-87cf-4396-ba5f-58b1f3e04f93"
      },
      "source": [
        "#Import Second Dataset\n",
        "url_two = 'https://drive.google.com/file/d/1xMEtidbapgBLs82ijoJvk0FsoPlL76yG/view?usp=sharing'\n",
        "file_id_two = url_two.split('/')[-2]\n",
        "csv_url_two = 'https://drive.google.com/uc?id=' + file_id_two\n",
        "df_two = pd.read_csv(csv_url_two)\n",
        "df_two.head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>user_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>406651200</td>\n",
              "      <td>2021-04-30 00:52:22</td>\n",
              "      <td>b\\'RT @ThatUmbrella: Advocates of #metoo shoul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>b\"1062082121353830402</td>\n",
              "      <td>2021-04-30 00:52:06</td>\n",
              "      <td>Boo another report while casualties pile up! Y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>957024565150011393</td>\n",
              "      <td>2021-04-30 00:51:51</td>\n",
              "      <td>b\"RT @MsAmyMacPherson: 1/9 There\\'s a SUPER HU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1164570123111292928</td>\n",
              "      <td>2021-04-30 00:51:37</td>\n",
              "      <td>b\"RT @RaquelDancho: Important to note: if the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>b\"1928003306</td>\n",
              "      <td>2021-04-30 00:50:49</td>\n",
              "      <td>RT @Aspasia_1: Basically .@MetOpera could have...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ...                                               text\n",
              "0      1  ...  b\\'RT @ThatUmbrella: Advocates of #metoo shoul...\n",
              "1      2  ...  Boo another report while casualties pile up! Y...\n",
              "2      3  ...  b\"RT @MsAmyMacPherson: 1/9 There\\'s a SUPER HU...\n",
              "3      4  ...  b\"RT @RaquelDancho: Important to note: if the ...\n",
              "4      5  ...  RT @Aspasia_1: Basically .@MetOpera could have...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35cp8CTG2C6q",
        "outputId": "feb44813-0226-4820-a27f-c1443bb232c4"
      },
      "source": [
        "print(\"Shape of 2nd period data-> \", df_two.shape)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of 2nd period data->  (8900, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m3AXL161vQR"
      },
      "source": [
        "# 3rd period (29 Apr - 05 May 2021)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "7NVfR0Xp1R4m",
        "outputId": "230d166b-e506-4fbd-b769-837344917276"
      },
      "source": [
        "#Import Third Dataset\n",
        "url_three = 'https://drive.google.com/file/d/1vNVBMchza3792vB16pGQwzHf65eJYlOB/view?usp=sharing'\n",
        "file_id_three = url_three.split('/')[-2]\n",
        "csv_url_three = 'https://drive.google.com/uc?id=' + file_id_three\n",
        "df_three = pd.read_csv(csv_url_three)\n",
        "df_three.head()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>user_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>b\"1256542308591378433</td>\n",
              "      <td>2021-05-05 23:34:50</td>\n",
              "      <td>RT @BombshellDAILY: REPUBLICAN BRUTALLY RAPES ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>14982231</td>\n",
              "      <td>2021-05-05 23:33:34</td>\n",
              "      <td>b\"Anthony Kiedis mocked those fighting Bin Lad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>b\"711294667</td>\n",
              "      <td>2021-05-05 23:32:57</td>\n",
              "      <td>RT @edrormba: Palestinian-American brings #MeT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>b\"925362823114485765</td>\n",
              "      <td>2021-05-05 23:32:57</td>\n",
              "      <td>RT @bette_oh: And, just like that, the #MeToo ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>b\"2323751900</td>\n",
              "      <td>2021-05-05 23:31:54</td>\n",
              "      <td>This guy was in #MeToo right?? https://t.co/zZ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ...                                               text\n",
              "0      1  ...  RT @BombshellDAILY: REPUBLICAN BRUTALLY RAPES ...\n",
              "1      2  ...  b\"Anthony Kiedis mocked those fighting Bin Lad...\n",
              "2      3  ...  RT @edrormba: Palestinian-American brings #MeT...\n",
              "3      4  ...  RT @bette_oh: And, just like that, the #MeToo ...\n",
              "4      5  ...  This guy was in #MeToo right?? https://t.co/zZ...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTsyGjAH2Gcn",
        "outputId": "d091c9ca-960d-4e15-e5a3-37e37228f19a"
      },
      "source": [
        "print(\"Shape of 3rd period data-> \", df_three.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of 3rd period data->  (7100, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRHojNTC10XJ"
      },
      "source": [
        "# 4th period (05 May - 11 May 2021)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrv4iSrW1TT3"
      },
      "source": [
        "#Import Fourth Dataset\n",
        "url_three = ''\n",
        "file_id_four = url_four.split('/')[-2]\n",
        "csv_url_four = 'https://drive.google.com/uc?id=' + file_id_four\n",
        "df_four = pd.read_csv(csv_url_four)\n",
        "df_four.head()\n",
        "#SOON"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDsXoKwx2s_N"
      },
      "source": [
        "print(\"Shape of 4th period data-> \", df_four.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VFVaH9U3Gqz"
      },
      "source": [
        "# Combine All Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0grh5XLA30Ui"
      },
      "source": [
        "After we collected all data within time period, we combined it into a new dataframe. There are 4 columns: \n",
        "\n",
        "1.   'index' : index of tweets\n",
        "2.   'user_id' : user ID that make the tweet\n",
        "3.   'timestamp' : time when the user tweet \n",
        "4.   'text' : tweets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGYaFsaE1Wmx"
      },
      "source": [
        "#df = pd.concat([df_one, df_two, df_three, df_four])\n",
        "df = pd.concat([df_one, df_two, df_three])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "wM4N0BNO3T_6",
        "outputId": "5ab4c744-3264-46e2-c339-73698804fa2b"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>user_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>420319697</td>\n",
              "      <td>2021-04-23 23:20:32</td>\n",
              "      <td>b\\'\"The ironies of the #MeToo movement are too...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>b\"33979748</td>\n",
              "      <td>2021-04-23 23:20:23</td>\n",
              "      <td>RT @WomenReadWomen: Women in Kuwait have launc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>b\"2891085942</td>\n",
              "      <td>2021-04-23 23:20:19</td>\n",
              "      <td>RT @j_andreamolina: \\\\xe2\\\\x9a\\\\xa0\\\\xef\\\\xb8\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>b\"2383033227</td>\n",
              "      <td>2021-04-23 23:19:13</td>\n",
              "      <td>RT @SammiStitches: Charges brought against the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1060143967872917504</td>\n",
              "      <td>2021-04-23 23:18:41</td>\n",
              "      <td>b\"And the fourth presenter on 26th May is Hann...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ...                                               text\n",
              "0      1  ...  b\\'\"The ironies of the #MeToo movement are too...\n",
              "1      2  ...  RT @WomenReadWomen: Women in Kuwait have launc...\n",
              "2      3  ...  RT @j_andreamolina: \\\\xe2\\\\x9a\\\\xa0\\\\xef\\\\xb8\\...\n",
              "3      4  ...  RT @SammiStitches: Charges brought against the...\n",
              "4      5  ...  b\"And the fourth presenter on 26th May is Hann...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmRPPKHh3WCT",
        "outputId": "b482d679-823d-41d0-f842-61ebaa3b1fd2"
      },
      "source": [
        "print(\"Combined shape of all data-> \", df.shape)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Combined shape of all data->  (22600, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lzrA4n646pX",
        "outputId": "4277b81d-0de1-494a-d9be-747a4530a185"
      },
      "source": [
        "# Check null\n",
        "df.isnull().sum()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "index        0\n",
              "user_id      0\n",
              "timestamp    0\n",
              "text         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKyw1LCWCn4M",
        "outputId": "e9338cf8-7492-47dd-bf01-178f61617205"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 22600 entries, 0 to 7099\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   index      22600 non-null  int64 \n",
            " 1   user_id    22600 non-null  object\n",
            " 2   timestamp  22600 non-null  object\n",
            " 3   text       22600 non-null  object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 882.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTZrbe1M3jz4"
      },
      "source": [
        "# Drop Unnecessary Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PRzmMiE5GD5"
      },
      "source": [
        "We will use 'text' column to get the tweet because our analysis and project will be based on this column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "WPu8St1e5DdU",
        "outputId": "a883b110-b165-4f83-a05e-90dbe9406758"
      },
      "source": [
        "df = df.drop(columns=['index', 'user_id', 'timestamp'])\n",
        "df"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b\\'\"The ironies of the #MeToo movement are too...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RT @WomenReadWomen: Women in Kuwait have launc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT @j_andreamolina: \\\\xe2\\\\x9a\\\\xa0\\\\xef\\\\xb8\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @SammiStitches: Charges brought against the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b\"And the fourth presenter on 26th May is Hann...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7095</th>\n",
              "      <td>RT @brianlilley: In QP today, \\\\xe2\\\\x81\\\\xa6@...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7096</th>\n",
              "      <td>RT @shades_dirty: Stop police sexual violence ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7097</th>\n",
              "      <td>RT @GretchenCarlson: I\\\\xe2\\\\x80\\\\x99ll speak ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7098</th>\n",
              "      <td>RT @brianlilley: In QP today, \\\\xe2\\\\x81\\\\xa6@...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7099</th>\n",
              "      <td>RT @SenatorHousakos: In fairness, he also didn...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22600 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text\n",
              "0     b\\'\"The ironies of the #MeToo movement are too...\n",
              "1     RT @WomenReadWomen: Women in Kuwait have launc...\n",
              "2     RT @j_andreamolina: \\\\xe2\\\\x9a\\\\xa0\\\\xef\\\\xb8\\...\n",
              "3     RT @SammiStitches: Charges brought against the...\n",
              "4     b\"And the fourth presenter on 26th May is Hann...\n",
              "...                                                 ...\n",
              "7095  RT @brianlilley: In QP today, \\\\xe2\\\\x81\\\\xa6@...\n",
              "7096  RT @shades_dirty: Stop police sexual violence ...\n",
              "7097  RT @GretchenCarlson: I\\\\xe2\\\\x80\\\\x99ll speak ...\n",
              "7098  RT @brianlilley: In QP today, \\\\xe2\\\\x81\\\\xa6@...\n",
              "7099  RT @SenatorHousakos: In fairness, he also didn...\n",
              "\n",
              "[22600 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbjSqSE65tf9"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKgvTpvj6cr0"
      },
      "source": [
        "Here we can see for some tweets that there are still many contractions like 'RT', user ID, URL, and punctuations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmZLkWP55xlL",
        "outputId": "f76a0f87-1f98-4271-81c0-28c00ba20513"
      },
      "source": [
        "for index,text in enumerate(df['text'][50:60]):\n",
        "  print('Tweets %d:\\n'%(index+1),text)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tweets 1:\n",
            " RT @SammiStitches: Charges brought against the guy that smacked my ass: sexual assault and battery. Fuck around and find out. \\\\xf0\\\\x9f\\\\x91\\\\x8a#sexualAssau\\\\xe2\\\\x80\\\\xa6'\n",
            "Tweets 2:\n",
            " RT @SammiStitches: Charges brought against the guy that smacked my ass: sexual assault and battery. Fuck around and find out. \\\\xf0\\\\x9f\\\\x91\\\\x8a#sexualAssau\\\\xe2\\\\x80\\\\xa6'\n",
            "Tweets 3:\n",
            " RT @KellyPlu: Harassment, retaliation &amp\n",
            "Tweets 4:\n",
            " Looking forward 2 a panel chat @CityCynthia today about systemic violence of police women in Canada. I am grateful the team of women on the panel &amp\n",
            "Tweets 5:\n",
            " @ArunKrishnan_ This b...d is in #MeToo case, does not talk about it.'\n",
            "Tweets 6:\n",
            " This is the child that was born as a result of a statutory rape committed by NLRPD cop Tommy Norman. The mother was 15 when Officer Norman had sex with her and got her pregnant. NLRPD needs to address\n",
            "Tweets 7:\n",
            " RT @GIWLkings: EVENT: A new cultural reckoning? Gendered violence &amp\n",
            "Tweets 8:\n",
            " RT @gecko39: \\\\xe2\\\\x80\\\\x98The Tail of the Anita Hill Fury Got Us to #MeToo\\\\xe2\\\\x80\\\\x99\\\\n\\\\nRebecca Traister outside the Stonewall Inn in Manhattan.CreditCreditJames\\\\xe2\\\\x80\\\\xa6'\n",
            "Tweets 9:\n",
            " @KNARDHOCKS Oh no! That\\\\xe2\\\\x80\\\\x99s terrible. \\\\n\\\\nCan you please link the #MeToo thread?'\n",
            "Tweets 10:\n",
            " Turns out, it was Gary all along. #SasquatchOnHulu #MeToo https://t.co/XJ1A4CgSiO'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "j5Fk8HL56zfe",
        "outputId": "625e83cf-8885-4dc2-92c0-05689b2da77f"
      },
      "source": [
        "#Safe Clean (Cleaning the new line command before it get removed by the next regex)\n",
        "df['text'] =  [re.sub(r\"\\\\n\", \" \", str(j)) for j in df['text']]\n",
        "\n",
        "#Cleaning the 'b', Retweet, Mentions, Unicode (\\x08\\,\\xef\\,etc), and punctuation marks.\n",
        "df['text'] =  [re.sub(r\"^b|http\\S+|[0-9]\\/[0-9]|\\'|\\\"|\\:|\\;|\\.|\\,|RT|\\\\\\\\x[\\w][\\w]|\\@[\\w\\_]*|\\#[\\w]*|\\\\\", \n",
        "                           \"\", str(j)) for j in df['text']]\n",
        "\n",
        "#Cleaning the blank space at the start of the sentences after the 1st cleaning process, hashtag and other punctuation that remains\n",
        "df['text'] =  [re.sub(r\"^\\s*|\\=|\\-|\\#[\\w]*\\s?|[a-z]*\\#[\\w]*\\s?|[\\(\\)\\|\\!\\$\\?\\*]*|\\&amp\", \"\", str(j)) for j in df['text']]\n",
        "\n",
        "#Cleaning digits and words containing digits\n",
        "#df['text'] = [re.sub('\\w*\\d\\w*','', str(j)) for j in df['text']]\n",
        "\n",
        "#Adding space after slash\n",
        "df['text'] =  [re.sub(r\"\\/\", \" \", str(j)) for j in df['text']]\n",
        "df.head()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The ironies of the  movement are too painfully...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Women in Kuwait have launched a social media c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Triger Warning Raising Awareness of Sexual Ass...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Charges brought against the guy that smacked m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>And the fourth presenter on 26th May is Hannah...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  The ironies of the  movement are too painfully...\n",
              "1  Women in Kuwait have launched a social media c...\n",
              "2  Triger Warning Raising Awareness of Sexual Ass...\n",
              "3  Charges brought against the guy that smacked m...\n",
              "4  And the fourth presenter on 26th May is Hannah..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1jS0ua3680j"
      },
      "source": [
        "#Transform the text into lowercase\n",
        "df['text'] = df['text'].str.lower()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFAfPATS6-5V"
      },
      "source": [
        "#Drop any duplicate row\n",
        "df = df.drop_duplicates()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWRBkUGZ7CgA",
        "outputId": "b44db002-ebbe-4b03-a15d-3d5b4b11ab85"
      },
      "source": [
        "#Fill up the empty cells\n",
        "df['text'].replace('', np.nan, inplace=True)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4582: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FiWBh-F7Km3"
      },
      "source": [
        "As we can see now, all the constractions already removed and the text already transformed into lowercase text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9h9dr-j7Dw2",
        "outputId": "288155c6-09c1-4c40-8de9-27ddfae5a078"
      },
      "source": [
        "for index,text in enumerate(df['text'][50:60]):\n",
        "  print('Tweets %d:\\n'%(index+1),text)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tweets 1:\n",
            " he also had this app on his phones its used to hide messages within jpg ima\n",
            "Tweets 2:\n",
            " just one question where is   english teacher marka bodine 31 sexually abused boy under 14 for three years unt\n",
            "Tweets 3:\n",
            " these ladies have been facing sexual harassment and brutally tortured during interrogation    \n",
            "Tweets 4:\n",
            " where tf is    high school teacher monica young 24 admitted to repeatedly sexually assaulting a 14yearold hi\n",
            "Tweets 5:\n",
            " starship  sara 1985 grunt records on youtube      \n",
            "Tweets 6:\n",
            " the  movement including the brave women who have gone to court and the debut of the civil code have reinvigora\n",
            "Tweets 7:\n",
            " he also had this app on his phones its used to hide messages within jpg images     \n",
            "Tweets 8:\n",
            " the  movement including the brave women who have gone to court and the debut of the civil code have reinvigorated discussions about sexual harassment in china   \n",
            "Tweets 9:\n",
            " actually amazing to see  standing up to be counted with the  and decolonisation sessions massive respect to the speakers who have given us a lot to think about time to decolonise\n",
            "Tweets 10:\n",
            " please believe my story we must believe all victims not silence them  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "dRM0dvI686lL",
        "outputId": "e2fdba1f-4f06-4edc-fa3c-e4bcfc38a05a"
      },
      "source": [
        "#Create Index\n",
        "df['index'] = range(0, len(df.index), 1)\n",
        "df.head()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the ironies of the  movement are too painfully...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>women in kuwait have launched a social media c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>triger warning raising awareness of sexual ass...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>charges brought against the guy that smacked m...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>and the fourth presenter on 26th may is hannah...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  index\n",
              "0  the ironies of the  movement are too painfully...      0\n",
              "1  women in kuwait have launched a social media c...      1\n",
              "2  triger warning raising awareness of sexual ass...      2\n",
              "3  charges brought against the guy that smacked m...      3\n",
              "4  and the fourth presenter on 26th may is hannah...      4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "_IAKGAKDDDlQ",
        "outputId": "3a36f2fc-7f79-4e3b-90aa-309d1087d396"
      },
      "source": [
        "#creating the word count column\n",
        "df['word_count'] = df['text'].apply(lambda x: len(str(x).split()))\n",
        "df.head()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>index</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the ironies of the  movement are too painfully...</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>women in kuwait have launched a social media c...</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>triger warning raising awareness of sexual ass...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>charges brought against the guy that smacked m...</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>and the fourth presenter on 26th may is hannah...</td>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  index  word_count\n",
              "0  the ironies of the  movement are too painfully...      0          31\n",
              "1  women in kuwait have launched a social media c...      1          18\n",
              "2  triger warning raising awareness of sexual ass...      2          11\n",
              "3  charges brought against the guy that smacked m...      3          18\n",
              "4  and the fourth presenter on 26th may is hannah...      4          32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z174wGrBTMR",
        "outputId": "8d51bb64-419c-4631-835d-3cf594d29b72"
      },
      "source": [
        "# Shape of cleaned data\n",
        "print(\"Shape of cleaned data-> \", df.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of cleaned data->  (8738, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAvPnlcDBeT_"
      },
      "source": [
        "Shape of each period data:\n",
        "\n",
        "\n",
        "1.   1st period : 6600\n",
        "2.   2nd period : 8900\n",
        "3.   3rd period : 7100\n",
        "4.   4th period : \n",
        "\n",
        "**TOTAL: 22600 tweets**\n",
        "\n",
        "After we cleaned the data, we only get **8738** tweets that we can use for training model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vJ4rMy79N2R"
      },
      "source": [
        "# Stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV1rz6LRLOM8"
      },
      "source": [
        "(ini pake Spacy stopwords) Versi 1: https://www.analyticsvidhya.com/blog/2020/04/beginners-guide-exploratory-data-analysis-text-data/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c9Kj4ElIUBB",
        "outputId": "6b08497a-6d45-45cf-9075-078a3f7cdc16"
      },
      "source": [
        "# Dictionary of English Contractions\n",
        "contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\n",
        "                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\n",
        "                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n",
        "                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n",
        "                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
        "                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n",
        "                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n",
        "                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n",
        "                     \"I'd\": \"I would\", \"I'd've\": \"I would have\",\"I'll\": \"I will\",\n",
        "                     \"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\", \"isn't\": \"is not\",\n",
        "                     \"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n",
        "                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n",
        "                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n",
        "                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n",
        "                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
        "                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n",
        "                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
        "                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n",
        "                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n",
        "                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n",
        "                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n",
        "                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n",
        "                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n",
        "                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n",
        "                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n",
        "                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n",
        "                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n",
        "                     \"what'll've\": \"what will have\",\"what're\": \"what are\", \"what've\": \"what have\",\n",
        "                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n",
        "                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n",
        "                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n",
        "                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n",
        "                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
        "                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
        "                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n",
        "                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n",
        "                     \"you've\": \"you have\"}\n",
        "\n",
        "# Regular expression for finding contractions\n",
        "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
        "\n",
        "# Function for expanding contractions\n",
        "def expand_contractions(text,contractions_dict=contractions_dict):\n",
        "  def replace(match):\n",
        "    return contractions_dict[match.group(0)]\n",
        "  return contractions_re.sub(replace, text)\n",
        "\n",
        "# Expanding Contractions in the reviews\n",
        "df['text']=df['text'].apply(lambda x:expand_contractions(str(x)))\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u76APbQbIomi",
        "outputId": "56aa80f7-8f16-46d4-80aa-6af74b12b704"
      },
      "source": [
        "# Importing spacy\n",
        "import spacy\n",
        "\n",
        "# Loading model\n",
        "nlp = spacy.load('en_core_web_sm',disable=['parser', 'ner'])\n",
        "\n",
        "# Lemmatization with stopwords removal\n",
        "df['lemmatized']=df['text'].apply(lambda x: ' '.join([token.lemma_ for token in list(nlp(x)) if (token.is_stop==False)]))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VqYeIyjPKFSM",
        "outputId": "304780ef-de4c-4c64-b400-df1008ae7573"
      },
      "source": [
        "df_grouped=df[['index','lemmatized']].groupby(by='index').agg(lambda x:' '.join(x))\n",
        "df_grouped.head()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemmatized</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>irony   movement painfully obvious spearhead h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>woman kuwait launch social medium campaign dem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>triger warning raise awareness sexual assault ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>charge bring guy smack ass sexual assault batt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fourth presenter 26th hannah baylor phd studen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              lemmatized\n",
              "index                                                   \n",
              "0      irony   movement painfully obvious spearhead h...\n",
              "1      woman kuwait launch social medium campaign dem...\n",
              "2      triger warning raise awareness sexual assault ...\n",
              "3      charge bring guy smack ass sexual assault batt...\n",
              "4      fourth presenter 26th hannah baylor phd studen..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vhFhP54AKYuM",
        "outputId": "cd1e3b22-b17e-425b-87f3-60a7fe394426"
      },
      "source": [
        "# Creating Document Term Matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer(analyzer='word')\n",
        "data=cv.fit_transform(df_grouped['lemmatized'])\n",
        "df_dtm = pd.DataFrame(data.toarray(), columns=cv.get_feature_names())\n",
        "df_dtm.index=df_grouped.index\n",
        "df_dtm.head(3)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>000</th>\n",
              "      <th>0021</th>\n",
              "      <th>01</th>\n",
              "      <th>03</th>\n",
              "      <th>0551</th>\n",
              "      <th>06</th>\n",
              "      <th>0746845220</th>\n",
              "      <th>075</th>\n",
              "      <th>08</th>\n",
              "      <th>0808</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>1000</th>\n",
              "      <th>10000</th>\n",
              "      <th>100000</th>\n",
              "      <th>100k</th>\n",
              "      <th>100s</th>\n",
              "      <th>103</th>\n",
              "      <th>105000squarefoot</th>\n",
              "      <th>1057</th>\n",
              "      <th>109</th>\n",
              "      <th>10k</th>\n",
              "      <th>10th</th>\n",
              "      <th>10yearold</th>\n",
              "      <th>11</th>\n",
              "      <th>110</th>\n",
              "      <th>113</th>\n",
              "      <th>1130</th>\n",
              "      <th>11day</th>\n",
              "      <th>11june</th>\n",
              "      <th>11p</th>\n",
              "      <th>12</th>\n",
              "      <th>120</th>\n",
              "      <th>1200</th>\n",
              "      <th>120000</th>\n",
              "      <th>1200100pm</th>\n",
              "      <th>12022022</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>12203</th>\n",
              "      <th>...</th>\n",
              "      <th>yp</th>\n",
              "      <th>yr</th>\n",
              "      <th>yrs</th>\n",
              "      <th>yrsattani</th>\n",
              "      <th>yrself</th>\n",
              "      <th>yukke</th>\n",
              "      <th>yummy</th>\n",
              "      <th>yup</th>\n",
              "      <th>yvette</th>\n",
              "      <th>z00mb0</th>\n",
              "      <th>zablocki</th>\n",
              "      <th>zaddy</th>\n",
              "      <th>zaf</th>\n",
              "      <th>zafar</th>\n",
              "      <th>zainab</th>\n",
              "      <th>zak</th>\n",
              "      <th>zakaria</th>\n",
              "      <th>zalil</th>\n",
              "      <th>zay</th>\n",
              "      <th>zealot</th>\n",
              "      <th>zebra</th>\n",
              "      <th>zehr</th>\n",
              "      <th>zeirings</th>\n",
              "      <th>zeitgeist</th>\n",
              "      <th>zemo</th>\n",
              "      <th>zenkus</th>\n",
              "      <th>zenobias</th>\n",
              "      <th>zero</th>\n",
              "      <th>zerotolerance</th>\n",
              "      <th>zhaos</th>\n",
              "      <th>zhe</th>\n",
              "      <th>ziere</th>\n",
              "      <th>ziering</th>\n",
              "      <th>zimmerman</th>\n",
              "      <th>zoe</th>\n",
              "      <th>zoepost</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zu</th>\n",
              "      <th>zurich</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 12096 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       000  0021  01  03  0551  06  ...  zoe  zoepost  zone  zoom  zu  zurich\n",
              "index                               ...                                      \n",
              "0        0     0   0   0     0   0  ...    0        0     0     0   0       0\n",
              "1        0     0   0   0     0   0  ...    0        0     0     0   0       0\n",
              "2        0     0   0   0     0   0  ...    0        0     0     0   0       0\n",
              "\n",
              "[3 rows x 12096 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6w8P2Uk6KvVd",
        "outputId": "4cb99577-d5ab-47b6-b869-022117515dd3"
      },
      "source": [
        "# Importing wordcloud for plotting word clouds and textwrap for wrapping longer text\n",
        "from wordcloud import WordCloud\n",
        "from textwrap import wrap\n",
        "\n",
        "# Function for generating word clouds\n",
        "def generate_wordcloud(data,title):\n",
        "  wc = WordCloud(width=400, height=330, max_words=150,colormap=\"Dark2\").generate_from_frequencies(data)\n",
        "  plt.figure(figsize=(10,8))\n",
        "  plt.imshow(wc, interpolation='bilinear')\n",
        "  plt.axis(\"off\")\n",
        "  plt.title('\\n'.join(wrap(title,60)),fontsize=13)\n",
        "  plt.show()\n",
        "  \n",
        "# Transposing document term matrix\n",
        "df_dtm=df_dtm.transpose()\n",
        "\n",
        "# Plotting word cloud for each product\n",
        "for index,product in enumerate(df_dtm.columns):\n",
        "  generate_wordcloud(df_dtm[product].sort_values(ascending=False),product)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-09db7eea20be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Plotting word cloud for each product\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mproduct\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mgenerate_wordcloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dtm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-78-09db7eea20be>\u001b[0m in \u001b[0;36mgenerate_wordcloud\u001b[0;34m(data, title)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Function for generating word clouds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_wordcloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mwc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m330\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolormap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Dark2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[0;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelative_scaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m                 font_size = int(round((rs * (freq / float(last_freq))\n\u001b[0m\u001b[1;32m    465\u001b[0m                                        + (1 - rs)) * font_size))\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefer_horizontal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGS8n9noLSgv"
      },
      "source": [
        "(ini pake nltk stopwords)\n",
        "Versi 2: https://neptune.ai/blog/exploratory-data-analysis-natural-language-processing-tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIjYyhbnLvEV"
      },
      "source": [
        "Versi 3: https://github.com/briannalytle/reddit_nlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KcVcKlRMQbb"
      },
      "source": [
        "# Plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts7LuTJ0G8uF"
      },
      "source": [
        "# Conclusion"
      ]
    }
  ]
}